## Abstract

This paper evaluates whether a Graph Attention Network (GAT) can predict the next basketball action from NBA play-by-play data given the current game context and recent possession events. Each event is represented as a fully connected interaction graph over the ten on-court players, where node feature vectors combine learned player identity embeddings with engineered contextual and temporal features (e.g., score margin, clock, possession progress, and short event history). The resulting graph representation is used to predict the next game-level event label from a fixed action set. As an unstructured baseline, we evaluate a Large Language Model (LLM) (Mistral 7B) using zero-shot and few-shot prompting over textual play-by-play descriptions. Models are evaluated using Top-1 accuracy, Top-3 accuracy, macro-F1, and per-class confusion matrices. Results suggest that the LLM baseline captures coarse game flow but struggles with fine-grained event prediction, while the GAT learns useful relational structure.
